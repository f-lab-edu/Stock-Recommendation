{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb15928",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import scipy.sparse as sp\n",
    "from scipy.special import expit\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, DataLoader\n",
    "from torchfm.model.fm import FactorizationMachineModel \n",
    "from torchfm.model.wd import WideAndDeepModel\n",
    "from torchfm.model.dfm import DeepFactorizationMachineModel\n",
    "from sklearn.metrics import mean_squared_error, precision_score, recall_score\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415156a8",
   "metadata": {},
   "source": [
    "ALS 성능 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408fa41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"data/holdings_data.parquet\"   \n",
    "FACTORS = 16        \n",
    "REG = 0.1      \n",
    "ALPHA = 40\n",
    "ITERATIONS = 100\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8595090a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(DATA_PATH)[[\"CIK\", \"CUSIP\", \"TOP25_FLAG\"]]\n",
    "df[\"CIK_id\"],   _ = pd.factorize(df[\"CIK\"])\n",
    "df[\"CUSIP_id\"], _ = pd.factorize(df[\"CUSIP\"])\n",
    "\n",
    "USER_COL, ITEM_COL, VALUE_COL = \"CIK_id\", \"CUSIP_id\", \"TOP25_FLAG\"\n",
    "n_users, n_items = df[USER_COL].nunique(), df[ITEM_COL].nunique()\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=SEED, stratify=df[VALUE_COL])\n",
    "\n",
    "train_pos = train_df[train_df[VALUE_COL] > 0]\n",
    "\n",
    "train_mat = sp.coo_matrix(\n",
    "    (train_pos[VALUE_COL].astype(np.float32) * ALPHA,\n",
    "     (train_pos[USER_COL], train_pos[ITEM_COL])),\n",
    "    shape=(n_users, n_items)\n",
    ").tocsr()\n",
    "\n",
    "\n",
    "model = AlternatingLeastSquares(\n",
    "    factors = FACTORS,\n",
    "    regularization = REG,\n",
    "    alpha = ALPHA,\n",
    "    iterations = ITERATIONS,\n",
    "    random_state = SEED,\n",
    "    use_cg = True,\n",
    "    num_threads = 0\n",
    ")\n",
    "\n",
    "model.fit(train_mat, show_progress=True)          \n",
    "\n",
    "user_vecs = model.user_factors\n",
    "item_vecs = model.item_factors\n",
    "\n",
    "u_idx = test_df[USER_COL].values\n",
    "i_idx = test_df[ITEM_COL].values\n",
    "\n",
    "raw_scores = np.einsum(\"ij,ij->i\", user_vecs[u_idx], item_vecs[i_idx])\n",
    "y_prob = expit(raw_scores)\n",
    "y_true = test_df[VALUE_COL].values.astype(np.float32)\n",
    "y_label = (y_prob >= 0.5).astype(int)\n",
    "\n",
    "print(f\"AUC       : {roc_auc_score(y_true, y_prob):.4f}\")\n",
    "print(f\"Acc@0.5   : {accuracy_score(y_true, y_label):.4f}\")\n",
    "print(f\"Precision : {precision_score(y_true, y_label):.4f}\")\n",
    "print(f\"Recall    : {recall_score(y_true, y_label):.4f}\")\n",
    "print(f\"RMSE      : {np.sqrt(mean_squared_error(y_true, y_prob)):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10d2b59",
   "metadata": {},
   "source": [
    "torch-fm을 이용한 모델 성능 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044bb009",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH   = \"data/holdings_data.parquet\"\n",
    "BATCH_SIZE = 4096\n",
    "EPOCHS     = 100\n",
    "EMBED_DIM  = 16\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "FIELD_COLS = [\"CIK_id\", \"CUSIP_id\"]\n",
    "LABEL_COL  = \"TOP25_FLAG\"\n",
    "MLP_DIMS  = (64, 32)\n",
    "DROPOUT   = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadabdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockDataset(Dataset):\n",
    "    def __init__(self, frame):\n",
    "        self.X = frame[FIELD_COLS].values.astype(np.int64)\n",
    "        self.y = frame[LABEL_COL ].values.astype(np.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (torch.from_numpy(self.X[idx]), torch.tensor(self.y[idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36358265",
   "metadata": {},
   "source": [
    "Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad071c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(DATA_PATH)[[\"CIK\", \"CUSIP\", \"TOP25_FLAG\"]]\n",
    "df[\"CIK_id\"],   _ = pd.factorize(df[\"CIK\"])\n",
    "df[\"CUSIP_id\"], _ = pd.factorize(df[\"CUSIP\"])\n",
    "\n",
    "field_dims = np.array([df[c].nunique() for c in FIELD_COLS])\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df[LABEL_COL])\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    StockDataset(train_df),\n",
    "    batch_size=BATCH_SIZE, shuffle=True,\n",
    "    num_workers=0, pin_memory=True\n",
    ")\n",
    "test_loader  = DataLoader(\n",
    "    StockDataset(test_df ),\n",
    "    batch_size=BATCH_SIZE, shuffle=False,\n",
    "    num_workers=0, pin_memory=True\n",
    ")\n",
    "\n",
    "model = FactorizationMachineModel(\n",
    "    field_dims = field_dims,\n",
    "    embed_dim  = EMBED_DIM\n",
    ").to(DEVICE)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model.train(); running_loss = 0.0\n",
    "    for X, y in tqdm(train_loader, desc=f\"Epoch {epoch}/{EPOCHS}\"):\n",
    "        X, y = X.to(DEVICE), y.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(X).squeeze()\n",
    "        loss   = criterion(logits, y)\n",
    "        loss.backward(); optimizer.step()\n",
    "        running_loss += loss.item() * y.size(0)\n",
    "    print(f\"[{epoch:02d}] Train Loss = {running_loss / len(train_loader.dataset):.4f}\")\n",
    "\n",
    "model.eval(); y_true, y_pred = [], []\n",
    "with torch.no_grad():\n",
    "    for X, y in test_loader:\n",
    "        X = X.to(DEVICE)\n",
    "        probs = torch.sigmoid(model(X).squeeze()).cpu()\n",
    "        y_true.append(y)\n",
    "        y_pred.append(probs)\n",
    "\n",
    "y_true = torch.cat(y_true).numpy()\n",
    "y_prob = torch.cat(y_pred).numpy()\n",
    "y_pred_label = (y_prob >= 0.5).astype(int)\n",
    "\n",
    "precision = precision_score(y_true, y_pred_label)\n",
    "recall    = recall_score(y_true, y_pred_label)\n",
    "rmse      = np.sqrt(mean_squared_error(y_true, y_prob))\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"RMSE:      {rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f3fe4d",
   "metadata": {},
   "source": [
    "Wide&Deep 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3172349a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(DATA_PATH)[[\"CIK\", \"CUSIP\", \"TOP25_FLAG\"]]\n",
    "df[\"CIK_id\"], cik_uniques = pd.factorize(df[\"CIK\"])\n",
    "df[\"CUSIP_id\"], cusip_uniques = pd.factorize(df[\"CUSIP\"])\n",
    "\n",
    "field_dims = np.array([df[c].nunique() for c in FIELD_COLS])\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df[LABEL_COL])\n",
    "\n",
    "train_loader = DataLoader(StockDataset(train_df), batch_size=BATCH_SIZE, shuffle=True,  num_workers=0)\n",
    "test_loader  = DataLoader(StockDataset(test_df ), batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "model = WideAndDeepModel(\n",
    "    field_dims = field_dims,\n",
    "    embed_dim  = EMBED_DIM,\n",
    "    mlp_dims   = MLP_DIMS,\n",
    "    dropout    = DROPOUT\n",
    ").to(DEVICE)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for x, y in tqdm(train_loader, desc=f\"Epoch {epoch}/{EPOCHS}\"):\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x).squeeze()\n",
    "        loss = criterion(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item() * y.size(0)\n",
    "    print(f\"  ▸ train loss = {epoch_loss / len(train_loader.dataset):.4f}\")\n",
    "\n",
    "model.eval(); y_true, y_pred = [], []\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader:\n",
    "        x = x.to(DEVICE)\n",
    "        logits = model(x).squeeze().cpu()\n",
    "        y_true.append(y)\n",
    "        y_pred.append(torch.sigmoid(logits))\n",
    "y_true = torch.cat(y_true).numpy()\n",
    "y_pred = torch.cat(y_pred).numpy()\n",
    "\n",
    "print(f\"AUC  : {roc_auc_score(y_true, y_pred):.4f}\")\n",
    "print(f\"Acc@0.5: {accuracy_score(y_true, (y_pred >= 0.5)):.4f}\")\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, mean_squared_error\n",
    "\n",
    "y_pred_label = (y_pred >= 0.5).astype(int)\n",
    "\n",
    "precision = precision_score(y_true, y_pred_label)\n",
    "recall    = recall_score(y_true, y_pred_label)\n",
    "rmse      = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall   : {recall:.4f}\")\n",
    "print(f\"RMSE     : {rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cddba5",
   "metadata": {},
   "source": [
    "DeepFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254c5341",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(DATA_PATH)[[\"CIK\", \"CUSIP\", \"TOP25_FLAG\"]]\n",
    "df[\"CIK_id\"],   _ = pd.factorize(df[\"CIK\"])\n",
    "df[\"CUSIP_id\"], _ = pd.factorize(df[\"CUSIP\"])\n",
    "\n",
    "field_dims = np.array([df[c].nunique() for c in FIELD_COLS])\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df[LABEL_COL])\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    StockDataset(train_df),\n",
    "    batch_size=BATCH_SIZE, shuffle=True,\n",
    "    num_workers=0, pin_memory=True\n",
    ")\n",
    "test_loader  = DataLoader(\n",
    "    StockDataset(test_df ),\n",
    "    batch_size=BATCH_SIZE, shuffle=False,\n",
    "    num_workers=0, pin_memory=True\n",
    ")\n",
    "\n",
    "model = DeepFactorizationMachineModel(\n",
    "    field_dims = field_dims,\n",
    "    embed_dim  = EMBED_DIM,\n",
    "    mlp_dims   = MLP_DIMS,\n",
    "    dropout    = DROPOUT\n",
    ").to(DEVICE)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model.train(); running_loss = 0.0\n",
    "    for X, y in tqdm(train_loader, desc=f\"Epoch {epoch}/{EPOCHS}\"):\n",
    "        X, y = X.to(DEVICE), y.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(X).squeeze()\n",
    "        loss   = criterion(logits, y)\n",
    "        loss.backward(); optimizer.step()\n",
    "        running_loss += loss.item() * y.size(0)\n",
    "    print(f\"[{epoch:02d}] Train Loss = {running_loss / len(train_loader.dataset):.4f}\")\n",
    "\n",
    "model.eval(); y_true, y_pred = [], []\n",
    "with torch.no_grad():\n",
    "    for X, y in test_loader:\n",
    "        X = X.to(DEVICE)\n",
    "        probs = torch.sigmoid(model(X).squeeze()).cpu()\n",
    "        y_true.append(y); y_pred.append(probs)\n",
    "\n",
    "y_true = torch.cat(y_true).numpy()\n",
    "y_pred = torch.cat(y_pred).numpy()\n",
    "\n",
    "print(f\"AUC      : {roc_auc_score(y_true, y_pred):.4f}\")\n",
    "print(f\"Acc@0.5  : {accuracy_score(y_true, (y_pred >= 0.5)):.4f}\")\n",
    "\n",
    "y_pred_label = (y_pred >= 0.5).astype(int)\n",
    "\n",
    "precision = precision_score(y_true, y_pred_label)\n",
    "recall    = recall_score(y_true, y_pred_label)\n",
    "rmse      = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall   : {recall:.4f}\")\n",
    "print(f\"RMSE     : {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266d1a2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
