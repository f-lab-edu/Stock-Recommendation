{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fb15928",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, DataLoader\n",
    "from torchfm.model.fm import FactorizationMachineModel \n",
    "from torchfm.model.wd import WideAndDeepModel\n",
    "from torchfm.model.dfm import DeepFactorizationMachineModel\n",
    "from sklearn.metrics import mean_squared_error, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70ea23f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"data/holdings_data.parquet\")\n",
    "\n",
    "# 정수 인덱스 생성 \n",
    "df[\"CIK_idx\"], _ = pd.factorize(df[\"CIK\"])\n",
    "df[\"CUSIP_idx\"], _ = pd.factorize(df[\"CUSIP\"])\n",
    "field_dims = np.array([df[\"CIK_idx\"].nunique(), df[\"CUSIP_idx\"].nunique()], dtype=np.int64)\n",
    "\n",
    "X_all = df[[\"CIK_idx\", \"CUSIP_idx\"]].values.astype(\"int64\")\n",
    "y_all = df[\"hold\"].astype(\"float32\").values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2, random_state=42, stratify=y_all)\n",
    "\n",
    "X_tr_tensor = torch.from_numpy(X_train)\n",
    "y_tr_tensor = torch.from_numpy(y_train)\n",
    "\n",
    "X_te_tensor = torch.from_numpy(X_test)\n",
    "y_te_tensor = torch.from_numpy(y_test)\n",
    "\n",
    "train_dataset = TensorDataset(X_tr_tensor, y_tr_tensor)\n",
    "test_dataset  = TensorDataset(X_te_tensor, y_te_tensor)\n",
    "\n",
    "batch_size = 4096\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=batch_size, shuffle=False)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36358265",
   "metadata": {},
   "source": [
    "Factorization을 이용한 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ad071c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE      : 0.0012\n",
      "Precision : 1.0000\n",
      "Recall    : 1.0000\n"
     ]
    }
   ],
   "source": [
    "model = FactorizationMachineModel(field_dims, embed_dim=16).to(device)\n",
    "\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "n_epochs = 100\n",
    "\n",
    "model.train()\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    loss_sum, n = 0.0, 0\n",
    "    for X, y in train_loader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        preds = model(X).squeeze()\n",
    "        loss = criterion(preds, y)\n",
    "        optimizer.zero_grad(); loss.backward(); optimizer.step()\n",
    "        loss_sum += loss.item() * len(y); n += len(y)\n",
    "\n",
    "    #print(f\"[Epoch {epoch:02d}] Train BCE: {loss_sum / n:.4f}\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    preds, labs = [], []\n",
    "    for Xi, yi in test_loader:\n",
    "        preds.append(model(Xi.to(device)).cpu().numpy())\n",
    "        labs.append(yi.numpy())\n",
    "y_pred = np.concatenate(preds)\n",
    "y_true = np.concatenate(labs)\n",
    "\n",
    "rmse  = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "y_bin = (y_pred >= 0.5).astype(int)\n",
    "prec  = precision_score(y_true, y_bin, zero_division=0)\n",
    "rec   = recall_score(y_true, y_bin,    zero_division=0)\n",
    "\n",
    "print(f\"RMSE      : {rmse:.4f}\")\n",
    "print(f\"Precision : {prec:.4f}\")\n",
    "print(f\"Recall    : {rec:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f3fe4d",
   "metadata": {},
   "source": [
    "Wide&Deep 모델을 이용한 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3172349a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE      : 0.0000\n",
      "Precision : 1.0000\n",
      "Recall    : 1.0000\n"
     ]
    }
   ],
   "source": [
    "model = WideAndDeepModel(field_dims = field_dims, embed_dim = 16, mlp_dims = (64, 32), dropout = 0.2).to(device)\n",
    "\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "n_epochs = 100\n",
    "\n",
    "model.train()\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    loss_sum, n = 0.0, 0\n",
    "    for X, y in train_loader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        preds = model(X).squeeze()\n",
    "        loss = criterion(preds, y)\n",
    "        optimizer.zero_grad(); loss.backward(); optimizer.step()\n",
    "        loss_sum += loss.item() * len(y); n += len(y)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    preds, labs = [], []\n",
    "    for Xi, yi in test_loader:\n",
    "        preds.append(model(Xi.to(device)).cpu().numpy())\n",
    "        labs.append(yi.numpy())\n",
    "y_pred = np.concatenate(preds)\n",
    "y_true = np.concatenate(labs)\n",
    "\n",
    "rmse  = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "y_bin = (y_pred >= 0.5).astype(int)\n",
    "prec  = precision_score(y_true, y_bin, zero_division=0)\n",
    "rec   = recall_score(y_true, y_bin, zero_division=0)\n",
    "\n",
    "print(f\"RMSE      : {rmse:.4f}\")\n",
    "print(f\"Precision : {prec:.4f}\")\n",
    "print(f\"Recall    : {rec:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cddba5",
   "metadata": {},
   "source": [
    "DeepFM을 이용한 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "254c5341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE      : 0.0000\n",
      "Precision : 1.0000\n",
      "Recall    : 1.0000\n"
     ]
    }
   ],
   "source": [
    "model = DeepFactorizationMachineModel(field_dims = field_dims, embed_dim = 16, mlp_dims = (64, 32), dropout = 0.2).to(device)\n",
    "\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "n_epochs = 100\n",
    "\n",
    "model.train()\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    loss_sum, n = 0.0, 0\n",
    "    for X, y in train_loader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        preds = model(X).squeeze()\n",
    "        loss = criterion(preds, y)\n",
    "        optimizer.zero_grad(); loss.backward(); optimizer.step()\n",
    "        loss_sum += loss.item() * len(y); n += len(y)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    preds, labs = [], []\n",
    "    for Xi, yi in test_loader:\n",
    "        preds.append(model(Xi.to(device)).cpu().numpy())\n",
    "        labs.append(yi.numpy())\n",
    "y_pred = np.concatenate(preds)\n",
    "y_true = np.concatenate(labs)\n",
    "\n",
    "rmse  = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "y_bin = (y_pred >= 0.5).astype(int)\n",
    "prec  = precision_score(y_true, y_bin, zero_division=0)\n",
    "rec   = recall_score(y_true, y_bin,    zero_division=0)\n",
    "\n",
    "print(f\"RMSE      : {rmse:.4f}\")\n",
    "print(f\"Precision : {prec:.4f}\")\n",
    "print(f\"Recall    : {rec:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266d1a2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
